{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Traitement Automatique de texte en IA projet\n",
    "> \n",
    "> > Antoine Vidal-Mazuy - Yann Brault\n",
    "> > 28/12/2021 Université Côtes d'azur\n",
    "\n",
    "<br>\n",
    "\n",
    "> ## Introduction\n",
    ">\n",
    "> > blablzqdbd bzqjkdb qz\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "> ## Dataset utilisés\n",
    ">\n",
    "> > #### Datasets de base:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Base line:\n",
    ">\n",
    "> > #### Prédicteurs de base:\n",
    "> > > Pour commencer notre projet, nous avons fait deux systèmes de prédictions simples. <br>\n",
    "> > > De base, une classe est assignée à chaque avis. Si la note attribuée est supérieure ou égale à 12 alors on assigne l'avis à la classe 1 comme signe de bon jeu. <br>\n",
    "> > > En revanche, si la note est strictement inférieure à 12 alors, l'avis est catégorisé par la classe 0, celle des mauvais jeux. <br>\n",
    "> > > ##### Prédicteur par comptage de mots:\n",
    "> > > L'idée ici est plutôt naïve. Si le commentaire contient plus de mots au sens négatifs, alors on prédit le jeu comme étant mauvais. À l'inverse, <br>\n",
    "> > > si la condition énoncée n'est pas validée alors le jeu est considéré comme étant bon. <br>\n",
    "> > > Le code marche comme ceci:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102478/102478 [00:06<00:00, 16080.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15110, 4847], [48369, 34152]]\n",
      "cat 0: TP:15110, TN:64372, FP:48369, FN:4847\n",
      "\n",
      "cat 1: TP:34152, TN:83414, FP:4847, FN:48369\n",
      "\n",
      "accuracy: 0.64368358122073\n",
      "\n",
      "accuracy: 0.585493057720152\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "import pandas as pd\n",
    "\n",
    "def predict(data: pd.DataFrame) -> tuple[list[int], list[int]]:\n",
    "    classes_predicted = []\n",
    "    classes_base = []\n",
    "\n",
    "    for i in trange(data.shape[0]):\n",
    "        row = data.iloc[i]\n",
    "        neg = row['negative_words']\n",
    "        pos = row['positive_words']\n",
    "        \n",
    "        predict = 1\n",
    "        if neg > pos: \n",
    "            predict = 0\n",
    "        \n",
    "        base = row['classe_bon_mauvais']\n",
    "        classes_base.append(int(base))\n",
    "        classes_predicted.append(int(predict))\n",
    "    \n",
    "    return classes_base, classes_predicted\n",
    "    \n",
    "def compute_confusion_matrix(classes_base, classes_predicted):\n",
    "    \n",
    "    M = [[0, 0], [0, 0]]\n",
    "\n",
    "    for i in range(len(classes_base)):\n",
    "        M[classes_base[i]][classes_predicted[i]] += 1\n",
    "    \n",
    "    return M\n",
    "\n",
    "def accuracy(TN, TP, FN, FP):\n",
    "    size_list = len(TN)\n",
    "    accuracy_sum = 0\n",
    "    for i in range(size_list):\n",
    "        accuracy_sum += (TP[i] + TN[i]) / (TP[i] + TN[i] + FN[i] + FP[i])\n",
    "    return accuracy_sum / size_list\n",
    "\n",
    "def recall(TP, FN):\n",
    "    size_list = len(TP)\n",
    "    recall_sum = 0\n",
    "    for i in range(size_list):\n",
    "        recall_sum += TP[i] / (TP[i] + FN[i])\n",
    "    return recall_sum / size_list\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = pd.read_csv('dataset/csv/base_predictor.csv')\n",
    "    classes_base, classes_predicted = predict(data)\n",
    "    M = compute_confusion_matrix(classes_base, classes_predicted)\n",
    "    print(M)\n",
    "    TP = [0,0]\n",
    "    TN = [0,0]\n",
    "    FP = [0,0]\n",
    "    FN = [0,0]\n",
    "    Total = M[0][0] + M[0][1] + M[1][0] + M[1][1]\n",
    "\n",
    "    for i in range(2):\n",
    "        TP[i] = M[i][i]\n",
    "        for j in range(2):\n",
    "            FN[i] += M[i][j]\n",
    "            FP[i] += M[j][i]\n",
    "        \n",
    "        FN[i] -= M[i][i]\n",
    "        FP[i] -= M[i][i]\n",
    "        TN[i] = Total - FP[i] - FN[i] + TP[i]\n",
    "\n",
    "    for i in range(2):\n",
    "        print(f\"cat {i}: TP:{TP[i]}, TN:{TN[i]}, FP:{FP[i]}, FN:{FN[i]}\\n\")\n",
    "\n",
    "    print (f\"accuracy: {accuracy(TN, TP, FN, FP)}\\n\")\n",
    "    print (f\"accuracy: {recall(TP, FN)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> > > ##### Prédicteur toujours bon:\n",
    "> > > L'idée ici est plus que simple. Peu importe que la classe de base soit bonne ou mauvaise, on prédit toujours que le jeu est bon. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat 0: TP:0, TN:82521, FP:0, FN:19957\n",
      "\n",
      "cat 1: TP:82521, TN:165042, FP:19957, FN:0\n",
      "\n",
      "the globla accuracy is 0.87\n",
      "\n",
      "the globla recall is 0.50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_class(data): #here we will assign a class number according to the rate. 1 for good games and 2 for bad games.\n",
    "    classes_predicted = []\n",
    "    classes_base = []\n",
    "    predict = 1\n",
    "    for i in range(data.shape[0]):\n",
    "        row = data.iloc[i]\n",
    "        base = row['classe_bon_mauvais']\n",
    "        classes_base.append(int(base))\n",
    "        classes_predicted.append(int(predict))\n",
    "    return classes_base, classes_predicted\n",
    "\n",
    "def accuracy(TN, TP, FN, FP):\n",
    "    size_list = len(TN)\n",
    "    accuracy_sum = 0\n",
    "    for i in range(size_list):\n",
    "        accuracy_sum += (TP[i] + TN[i]) / (TP[i] + TN[i] + FN[i] + FP[i])\n",
    "    return accuracy_sum / size_list\n",
    "\n",
    "def recall(TP, FN):\n",
    "    size_list = len(TP)\n",
    "    recall_sum = 0\n",
    "    for i in range(size_list):\n",
    "        recall_sum += TP[i] / (TP[i] + FN[i])\n",
    "    return recall_sum / size_list\n",
    "\n",
    "def CM(classes_base, classes_predicted):\n",
    "    M = [[0, 0], [0, 0]]\n",
    "\n",
    "    for i in range(len(classes_base)):\n",
    "        M[classes_base[i]][classes_predicted[i]] += 1\n",
    "\n",
    "    TP = [0,0]\n",
    "    TN = [0,0]\n",
    "    FP = [0,0]\n",
    "    FN = [0,0]\n",
    "    Total = M[0][0] + M[0][1] + M[1][0] + M[1][1]\n",
    "\n",
    "    for i in range(2):\n",
    "        TP[i] = M[i][i]\n",
    "        for j in range(2):\n",
    "            FN[i] += M[i][j]\n",
    "            FP[i] += M[j][i]\n",
    "        \n",
    "        FN[i] -= M[i][i]\n",
    "        FP[i] -= M[i][i]\n",
    "        TN[i] = Total - FP[i] - FN[i] + TP[i]\n",
    "\n",
    "    for i in range(2):\n",
    "        print(f\"cat {i}: TP:{TP[i]}, TN:{TN[i]}, FP:{FP[i]}, FN:{FN[i]}\\n\")\n",
    "\n",
    "    accu = accuracy(TN, TP, FN, FP)\n",
    "    rec = recall(TP, FN)\n",
    "\n",
    "    print(f\"the globla accuracy is {accu:.2f}\\n\")\n",
    "    print(f\"the globla recall is {rec:.2f}\\n\")\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    my_data = pd.read_csv(\"./dataset/csv/base_predictor.csv\")\n",
    "    classes_base, classes_predicted = predict_class(my_data)\n",
    "    CM(classes_base, classes_predicted)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c173755a5ba393296f2071232f17e08cd35a01c17008ca36d29007ad2d1a854"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
